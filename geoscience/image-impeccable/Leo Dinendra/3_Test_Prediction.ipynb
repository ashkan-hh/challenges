{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "317194fc-0e33-4caf-935f-a400fe933eb5",
   "metadata": {},
   "source": [
    "# Image Impeccable Challenge: Journey to Clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330005b-a088-4f44-9dcf-af89c5f9785d",
   "metadata": {},
   "source": [
    "## Part 3 : Prediction of Test Data set for Final Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04966b-1f0b-4224-8388-0103a654c86a",
   "metadata": {},
   "source": [
    "By: Leo Dinendra\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7722b-8d68-4496-847c-847da3388c72",
   "metadata": {},
   "source": [
    "The final submission result file will be saved in the **submission_path** directory, which by default is called the *submission_files* folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c8408-08b9-4851-86ba-3eb2dee7674e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 0. General Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37ce4b-b7fb-47ba-b01e-62bad7fcf6e4",
   "metadata": {},
   "source": [
    "Put the location of holdout test dataset folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee40cd19-46c2-4a7a-b8ce-4fa368e34589",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = './test_data/'                              # folder where the npy test dataset located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9926f610-727b-43d9-932b-1462825f08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoint/unet_checkpoint_best.pth'  # training checkpoint used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06aef56-ccdc-409e-9f81-023a73d89883",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_path = './predictions/'                          # temporary prediction files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aeb236f-0a78-4f11-b2e8-c557097d7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = './submission_files'                       # final submission format file path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7cc1ab-0a49-4422-8b90-80fa83ac0d3f",
   "metadata": {},
   "source": [
    "Loading Packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f11c95-1f23-4a76-a77b-4e57bd1427f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import pprint as pp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as sk_ssim\n",
    "from utils import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5411d70-8521-4f4d-ad6b-67d4aa37183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\miniconda3\\envs\\test_sub\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9743bd6c-3633-48e1-8065-66b5ddfb6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(predictions_path):\n",
    "    os.makedirs(predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803e97ee-5086-4740-bd2d-609d46392344",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(submission_path):\n",
    "    os.makedirs(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4052365d-feed-4fc4-9c61-66a6ba93a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c230041-5a85-443c-acc9-e8b44ba777fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_files = []\n",
    "for root, dirs, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.npy'):\n",
    "            full_path = os.path.join(root, file)\n",
    "            pred_files.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1020150f-964a-4c27-a523-e8f676844f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 15 files.\n"
     ]
    }
   ],
   "source": [
    "print('there are', len(pred_files), 'files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60a822-edfd-4b1d-a3a2-5e4cc24d7cae",
   "metadata": {},
   "source": [
    "### Loading Model & Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "904f0e94-02cc-40e8-98a6-72d265e13dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # ResNet as the encoder backbone\n",
    "    encoder_weights=None,           # start training from scratch for denoising\n",
    "    in_channels=1,                  \n",
    "    classes=1,                      \n",
    "    encoder_depth=4,\n",
    "    decoder_channels=(128, 64, 32, 16),  # adjusted best decoder channel for this case\n",
    "    decoder_use_batchnorm=True,     \n",
    "    decoder_attention_type='scse'     # adding attention in decoder\n",
    ")\n",
    "model.segmentation_head = nn.Sequential(\n",
    "     nn.Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "     nn.ReLU() \n",
    ")\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac35be7a-979b-401b-bd09-b84d9f4ff781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b4613-e320-42df-90f5-8915c88040a7",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1572167-853c-4ffd-a144-cdfbb9295dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.008 # threshold for predicting only part after water column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7ede1cd-904b-49b7-b45c-ed7773c4db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 19.77it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 24.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 19.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 19.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 24.73it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 19.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 24.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 3 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 19.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 24.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 19.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 4 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 19.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 18.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:15<00:00, 18.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 6 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:14<00:00, 21.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 7 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 8 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 21.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:17<00:00, 17.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:14<00:00, 20.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 9 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 17.94it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.99it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:17<00:00, 17.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:14<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 11 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.08it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 12 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.23it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 17.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 13 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.08it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 14 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 15 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:17<00:00, 17.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for i_file in range(len(pred_files) ):\n",
    "    print('Predicting', i_file+1, 'of', len(pred_files) )\n",
    "    pred_noise = np.load(pred_files[i_file], allow_pickle=True, mmap_mode=\"r+\")\n",
    "    \n",
    "    # check if the array already has the correct shape\n",
    "    target_shape = (1259, 300, 300)\n",
    "    if pred_noise.shape != target_shape:\n",
    "        pred_noise = np.transpose(pred_noise, axes=(2,1,0))\n",
    "    \n",
    "    #placeholder prediction cube for stacking\n",
    "    pred_clean = np.zeros_like(pred_noise)\n",
    "    pred_clean2 = np.zeros_like(pred_noise)\n",
    "    pred_clean3 = np.zeros_like(pred_noise)\n",
    "    pred_clean4 = np.zeros_like(pred_noise)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(300)):\n",
    "            seis_noise = pred_noise[:,:,i]\n",
    "            \n",
    "            #preprocess\n",
    "            noise_min = np.min(seis_noise)\n",
    "            noise_max = np.max(seis_noise)\n",
    "            seis_noise = (seis_noise - noise_min) / (noise_max - noise_min)\n",
    "            mean_noise = np.mean(seis_noise)\n",
    "            seis_noise = seis_noise - mean_noise + 0.5\n",
    "            diffnoise = np.diff(seis_noise, axis=0)\n",
    "            seis_noise_ori = seis_noise.copy()\n",
    "            seis_noise = cv2.resize(seis_noise, (320, 1280))\n",
    "            data = torch.tensor(seis_noise, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            \n",
    "            #prediction\n",
    "            outputs = model(data)\n",
    "            output_np = outputs[0, 0, :, :].cpu().numpy()\n",
    "            \n",
    "            #postprocess\n",
    "            output_np = cv2.resize(output_np, (300, 1259))\n",
    "            output_np_ori= output_np.copy()\n",
    "            scale = np.max(seis_noise_ori - 0.5, axis=0)/np.max(output_np_ori - 0.5, axis=0)\n",
    "            seis_noise_ori = seis_noise_ori - 0.5\n",
    "            seis_noise_ori = seis_noise_ori/scale\n",
    "            seis_noise_ori = seis_noise_ori + 0.5\n",
    "            for j in range(300):\n",
    "                thres = np.where(np.abs(diffnoise[:,j]) > threshold)[0][0]\n",
    "                output_np[:thres, j] = seis_noise_ori[:thres, j]\n",
    "            output_np = output_np - 0.5 + mean_noise \n",
    "            output_np = output_np * (noise_max - noise_min) + noise_min\n",
    "            pred_clean[:,:,i] = output_np\n",
    "            \n",
    "\n",
    "        for i in tqdm(range(300)):\n",
    "            seis_noise = pred_noise[:,i,:]\n",
    "            \n",
    "            #preprocess\n",
    "            noise_min = np.min(seis_noise)\n",
    "            noise_max = np.max(seis_noise)\n",
    "            seis_noise = (seis_noise - noise_min) / (noise_max - noise_min)\n",
    "            mean_noise = np.mean(seis_noise)\n",
    "            seis_noise = seis_noise - mean_noise + 0.5\n",
    "            diffnoise = np.diff(seis_noise, axis=0)\n",
    "            seis_noise_ori = seis_noise.copy()\n",
    "            seis_noise = cv2.resize(seis_noise, (320, 1280))\n",
    "            data = torch.tensor(seis_noise, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            \n",
    "            #prediction\n",
    "            outputs = model(data)\n",
    "            output_np = outputs[0, 0, :, :].cpu().numpy()\n",
    "            \n",
    "            #postprocess\n",
    "            output_np = cv2.resize(output_np, (300, 1259))\n",
    "            output_np_ori= output_np.copy()\n",
    "            scale = np.max(seis_noise_ori - 0.5, axis=0)/np.max(output_np_ori - 0.5, axis=0)\n",
    "            seis_noise_ori = seis_noise_ori - 0.5\n",
    "            seis_noise_ori = seis_noise_ori/scale\n",
    "            seis_noise_ori = seis_noise_ori + 0.5\n",
    "            for j in range(300):\n",
    "                thres = np.where(np.abs(diffnoise[:,j]) > threshold)[0][0]\n",
    "                output_np[:thres, j] = seis_noise_ori[:thres, j]\n",
    "            output_np = output_np - 0.5 + mean_noise \n",
    "            output_np = output_np * (noise_max - noise_min) + noise_min\n",
    "            \n",
    "            pred_clean2[:,i,:] = output_np \n",
    "            \n",
    "        for i in tqdm(range(300)):\n",
    "            seis_noise = pred_noise[:,:,i]\n",
    "            seis_noise = np.fliplr(seis_noise)\n",
    "            \n",
    "            #preprocess\n",
    "            noise_min = np.min(seis_noise)\n",
    "            noise_max = np.max(seis_noise)\n",
    "            seis_noise = (seis_noise - noise_min) / (noise_max - noise_min)\n",
    "            mean_noise = np.mean(seis_noise)\n",
    "            seis_noise = seis_noise - mean_noise + 0.5\n",
    "            diffnoise = np.diff(seis_noise, axis=0)\n",
    "            seis_noise_ori = seis_noise.copy()\n",
    "            seis_noise = cv2.resize(seis_noise, (320, 1280))\n",
    "            data = torch.tensor(seis_noise, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            \n",
    "            #prediction\n",
    "            outputs = model(data)\n",
    "            output_np = outputs[0, 0, :, :].cpu().numpy()\n",
    "            \n",
    "            #postprocess\n",
    "            output_np = cv2.resize(output_np, (300, 1259))\n",
    "            output_np_ori= output_np.copy()\n",
    "            scale = np.max(seis_noise_ori - 0.5, axis=0)/np.max(output_np_ori - 0.5, axis=0)\n",
    "            seis_noise_ori = seis_noise_ori - 0.5\n",
    "            seis_noise_ori = seis_noise_ori/scale\n",
    "            seis_noise_ori = seis_noise_ori + 0.5\n",
    "            for j in range(300):\n",
    "                thres = np.where(np.abs(diffnoise[:,j]) > threshold)[0][0]\n",
    "                output_np[:thres, j] = seis_noise_ori[:thres, j]\n",
    "            output_np = output_np - 0.5 + mean_noise \n",
    "            output_np = output_np * (noise_max - noise_min) + noise_min\n",
    "            \n",
    "            output_np = np.fliplr(output_np)\n",
    "            pred_clean3[:,:,i] = output_np\n",
    "            \n",
    "        for i in tqdm(range(300)):\n",
    "            seis_noise = pred_noise[:,i,:]\n",
    "            seis_noise = np.fliplr(seis_noise)\n",
    "            \n",
    "            #preprocess\n",
    "            noise_min = np.min(seis_noise)\n",
    "            noise_max = np.max(seis_noise)\n",
    "            seis_noise = (seis_noise - noise_min) / (noise_max - noise_min)\n",
    "            mean_noise = np.mean(seis_noise)\n",
    "            seis_noise = seis_noise - mean_noise + 0.5\n",
    "            diffnoise = np.diff(seis_noise, axis=0)\n",
    "            seis_noise_ori = seis_noise.copy()\n",
    "            seis_noise = cv2.resize(seis_noise, (320, 1280))\n",
    "            data = torch.tensor(seis_noise, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            \n",
    "            #prediction\n",
    "            outputs = model(data)\n",
    "            output_np = outputs[0, 0, :, :].cpu().numpy()\n",
    "            \n",
    "            #postprocess\n",
    "            output_np = cv2.resize(output_np, (300, 1259))\n",
    "            output_np_ori= output_np.copy()\n",
    "            scale = np.max(seis_noise_ori - 0.5, axis=0)/np.max(output_np_ori - 0.5, axis=0)\n",
    "            seis_noise_ori = seis_noise_ori - 0.5\n",
    "            seis_noise_ori = seis_noise_ori/scale\n",
    "            seis_noise_ori = seis_noise_ori + 0.5\n",
    "            for j in range(300):\n",
    "                thres = np.where(np.abs(diffnoise[:,j]) > threshold)[0][0]\n",
    "                output_np[:thres, j] = seis_noise_ori[:thres, j]\n",
    "            output_np = output_np - 0.5 + mean_noise \n",
    "            output_np = output_np * (noise_max - noise_min) + noise_min\n",
    "            \n",
    "            output_np = np.fliplr(output_np)\n",
    "            pred_clean4[:,i,:] = output_np \n",
    "            \n",
    "        pred_clean = (pred_clean + pred_clean2 + pred_clean3 + pred_clean4)/4  \n",
    "        np.save(predictions_path+pred_files[i_file].split('/')[2].split('\\\\')[0]+'_gt.npy', \n",
    "                pred_clean.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2ed5e-dc6c-4a0e-81c9-b1a5f26e556a",
   "metadata": {},
   "source": [
    "### Submission File Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41505b-4ceb-4066-9183-da0bce0a7560",
   "metadata": {},
   "source": [
    "The ThinkOnward team has provided challengers with submission file generation code, which can be found in the `utils.py` script. There are two functions provided that will be useful; `create_single_submission()` and `create_submission()`.\n",
    "\n",
    "`create_single_submission()` allows you to create a single submission file for any number of volumes. This should be used for testing purposes. Once you have predictions from your model, you can create a single submission file to test in the scoring function provided in the `Evaluation` section. \n",
    "\n",
    "`create_submission()` should be used as the final output submission file for challengers to provide to the scoring page.\n",
    "\n",
    "Below is an example of how you might load some training data and create a submission file. While we encourage testing of the submission file generation and scoring code using training data, the final submission will be generated using the 15 test volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142a2c9-6b3d-4557-a46c-9ac35fdbf298",
   "metadata": {},
   "source": [
    "For the sake of testing, create 3 randomly generated predictions using Numpy and save them to the predictions folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b4c04-86a7-4a27-96d5-5768b10d25aa",
   "metadata": {},
   "source": [
    "example1 = np.random.rand(1259, 300, 300)\n",
    "example2 = np.random.rand(1259, 300, 300)\n",
    "example3 = np.random.rand(1259, 300, 300)\n",
    "np.save(\"./predictions/example1.npy\", example1)\n",
    "np.save(\"./predictions/example2.npy\", example2)\n",
    "np.save(\"./predictions/example3.npy\", example3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af9e6d-a9f6-4622-929c-306d4a19bcb1",
   "metadata": {},
   "source": [
    "Next, you'll use these test predictions to create the `seismic_filenames` and `predictions` lists that contain the required info to feed into `create_submission()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bbceaf1-3a3b-4230-aa35-843a8773f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-06-10_0d6402b1_gt.npy', '2024-06-10_1a4e5680_gt.npy', '2024-06-10_1b9a0096_gt.npy', '2024-06-10_2bd82c05_gt.npy', '2024-06-10_3b118e17_gt.npy', '2024-06-10_43537d46_gt.npy', '2024-06-10_662066f4_gt.npy', '2024-06-10_971ac6dd_gt.npy', '2024-06-10_9871c8c6_gt.npy', '2024-06-10_b7c329be_gt.npy', '2024-06-10_bfd43f22_gt.npy', '2024-06-10_c952ed24_gt.npy', '2024-06-10_cec3da7f_gt.npy', '2024-06-10_eb45f27e_gt.npy', '2024-06-11_f46c20fe_gt.npy']\n",
      "2024-06-10_0d6402b1_gt.npy loaded\n",
      "2024-06-10_1a4e5680_gt.npy loaded\n",
      "2024-06-10_1b9a0096_gt.npy loaded\n",
      "2024-06-10_2bd82c05_gt.npy loaded\n",
      "2024-06-10_3b118e17_gt.npy loaded\n",
      "2024-06-10_43537d46_gt.npy loaded\n",
      "2024-06-10_662066f4_gt.npy loaded\n",
      "2024-06-10_971ac6dd_gt.npy loaded\n",
      "2024-06-10_9871c8c6_gt.npy loaded\n",
      "2024-06-10_b7c329be_gt.npy loaded\n",
      "2024-06-10_bfd43f22_gt.npy loaded\n",
      "2024-06-10_c952ed24_gt.npy loaded\n",
      "2024-06-10_cec3da7f_gt.npy loaded\n",
      "2024-06-10_eb45f27e_gt.npy loaded\n",
      "2024-06-11_f46c20fe_gt.npy loaded\n"
     ]
    }
   ],
   "source": [
    "predictions_path = (\n",
    "    predictions_path  # Path to your predictions folder or training data folder\n",
    ")\n",
    "seismic_filenames = sorted(\n",
    "    [\n",
    "        file.split(\"/\")[0]\n",
    "        for path, dirs, files in os.walk(predictions_path)\n",
    "        for file in files\n",
    "        if file.endswith(\".npy\")\n",
    "    ]\n",
    ")  # ensure that the filenames are sorted\n",
    "print(seismic_filenames)\n",
    "\n",
    "predictions = []\n",
    "for seismic_filename in seismic_filenames:\n",
    "    seismic = np.load(f\"{predictions_path}{seismic_filename}\")\n",
    "    seismic = rescale_volume(seismic, low=0, high=100)#rescale, no clipping\n",
    "    predictions.append(seismic)\n",
    "    print(seismic_filename, \"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c2df7-a26f-4e3b-869e-2345bde4f87f",
   "metadata": {},
   "source": [
    "Let's say you want to create a single submission file just to test your model's quality. Here is code that creates one single submission file to feed into the scoring algorithm provided below. You can create your own ground truth file by using the denoised volumes provided to create a ground truth submission file for use in the scoring algorithm below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a96769ef-364a-429f-8d6e-829718bd9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seismic_filename, target in zip(seismic_filenames, predictions):\n",
    "    create_single_submission(\n",
    "        seismic_filename,\n",
    "        prediction=target,\n",
    "        submission_path=\"./submission_files/Final_Submission_Leo.npz\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ce543-04cb-49b2-b34e-d8b81bfe3539",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook is licensed under the [MIT License](./LICENSE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
